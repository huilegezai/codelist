# 到底可不可以使用join？

###### 如何优化Join速度

用小结果集驱动大结果集，减少外层循环的数据量，从而减少内层循环次数：
如果小结果集和大结果集连接的列都是索引列，mysql在内连接时也会选择用小结果集驱动大结果集，因为索引查询的成本是比较固定的，这时候外层的循环越少，join的速度便越快。
为匹配的条件增加索引：争取使用INLJ，减少内层表的循环次数
增大join buffer size的大小：当使用BNLJ时，一次缓存的数据越多，那么内层表循环的次数就越少
减少不必要的字段查询：
（1）当用到BNLJ时，字段越少，join buffer 所缓存的数据就越多，内层表的循环次数就越少；
（2）当用到INLJ时，如果可以不回表查询，即利用到覆盖索引，则可能可以提示速度。（未经验证，只是一个推论）



驱动表是走全表扫描，而被驱动表是走树搜索

1、使用join语句，性能比强行拆成多个单表执行SQl语句的性能要好

2、如果使用join语句的话，需要让小表做驱动表

###### 在Mysql的实现中，Nested-Loop Join有3种实现的算法：

Simple Nested-Loop Join：SNLJ，简单嵌套循环连接
Index Nested-Loop Join：INLJ，索引嵌套循环连接
Block Nested-Loop Join：BNLJ，缓存块嵌套循环连接 

Index Nested-Loop Join：和Block Nested-Loop Join的的时间复杂度是一样的，Block Nested-Loop Join是内存操作，速度上会快很多，性能也更好。

Block Nested-Loop Join算法下，选择哪个表作为驱动表都是一样的，因为

1、两个表都做一次全表扫描，所以总的扫描行数为M+N；

2、内存中的判断次数为M*N

BNLJ算法的执行逻辑是：

1、首先，将驱动表的数据全部读入内存join_buffer中，这里join_buffer是无序数组；

2、然后，顺序遍历被驱动表的所有行，每一行数据都跟join_buffer中的数据进行匹配，匹配成功则作为结果集的一部分返回。

SNLJ算法的执行逻辑是：顺序取出驱动表中的每一行数据，到被驱动表去做全表扫描匹配，匹配成功则作为结果集的一部分返回。

Simple Nested Loop Join 算法，其实也是把数据读到内存里，然后按照匹配条件进行判断，为什么性能差距会这么大呢？解释这个问题，需要用到 MySQL 中索引结构和 Buffer Pool 的相关知识点：

1、在对被驱动表做全表扫描的时候，如果数据没有在 Buffer Pool 中，就需要等待这部分数据从磁盘读入；从磁盘读入数据到内存中，会影响正常业务的 Buffer Pool 命中率，而且这个算法天然会对被驱动表的数据做多次访问，更容易将这些数据页放到 Buffer Pool 的头部（请参考第 35 篇文章中的相关内容)；

2、即使被驱动表数据都在内存中，每次查找“下一个记录的操作”，都是类似指针操作。而 join_buffer 中是数组，遍历的成本更低。

###### 分区表

创建表的时候，使用了数据分区相关的语法，存储数据的时候，存储引擎会根据分区规则将不同的数据存入不同的分区文件中。

使用分区表的劣劣势：

1、Mysql在第一次打开分区表的时候，需要访问所有的分区---打开的表较多，性能糟糕也可能报打开的表超过设置的问题。

2、在server层，认为这是同一张表。因此所有分区共同用同一个MDL锁---锁粒度大，影响并发度，站在Server看也是合理的，不过站在存储引擎的角度看就不合理了。

3、在引擎层，认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则，只访问必要的分区--被访问到的分区。

4：啥时候适合使用分区表？
单表过大时，使用时注意一下两点
4-1：分区并不是越细越好。实际上，单表或者单分区的数据一千万行，只要没有特别大的索引，对于现在的硬件能力来说都已经是小表了。
4-2：分区也不要提前预留太多，在使用之前预先创建即可。比如，如果是按月分区，每年年底时再把下一年度的 12 个新分区创建上即可。对于没有数据的历史分区，要及时的 drop 掉。
5：使用分区表，有其特点的根本原因？
对于Server层，分区表还是一个表
对于存储引擎层，分区表会是多张表

###### distinct 和 group by 的性能

`select a from t group by a order by null;
select distinct a from t;`

没有聚合函数时，distinct和group by这两条语句和执行流程是相同的，因此执行性能也相同。

执行流程：

1、创建一个临时表，临时表有一个字段a，并且在这个字段a上创建一个唯一索引；

2、遍历表t，依次取数据插入临时表中：

​    （1）如果发现唯一健冲突，就跳过；

​	（2）否则插入成功；

2、遍历完成后，将临时表作为结果集返回给客户端。

###### 短链接风暴

正常的短链接在连接到数据库后，执行很少的SQL语句就断开，下次需要的时候再重连，如果使用的是短链接，在业务高峰的时候，就可能出现连接数突然暴涨的情况出现，max_connections是控制数据库的连接数，超过这个值就会拒绝连接。

解决方法：

1、调高max_connections值；

风险：让让更多的连接都可以进来，那么系统的负载可能会进一步加大，大量的资源耗费在权限验证等逻辑上，结果可能是适得其反，已经连接的线程拿不到 CPU 资源去执行业务的 SQL 请求。

2、先处理掉那些占着连接但是不工作的线程。

风险：断开连接是损害的，先断开事务外空闲太久的连接，再考虑断开事务内空闲太久的连接。 从服务端断开，客户端在发起下次请求时报错。 从数据库端断开，从数据库端主动断开连接可能是有损的，尤其是有的应用端收到这个错误后，不重新连接，而是直接用这个已经不能用的句柄重试查询。这会导致从应用端看上去，“MySQL 一直没恢复”。作为DBA，即使只是一个断开连接的操作，也要确保通知到业务开发团队。

3、减少连接过程的消耗。

客户端在连接到数据库时，会获取数据库的权限验证的，连接过程会消耗掉大量的性能，所以我们可以去掉权限验证阶段，包括连接过程和语句执行过程在内

方法：重启数据库，并使用–skip-grant-tables 参数启动，但是风险极高，容易被攻击。

###### 慢查询性能问题

造成慢查询的原因有三：

1、索引没有设计好；

方法：紧急创建索引来解决

1. 在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引；
2. 执行主备切换；
3. 这时候主库是 B，备库是 A。在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引；

2、SQL语句没有写好；

使用存储过程，把SQL语句执行的时候使用到索引，也就是”查询重写“ 的功能，例如

```

mysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");

call query_rewrite.flush_rewrite_rules();
```

![img](https://static001.geekbang.org/resource/image/47/8a/47a1002cbc4c05c74841591d20f7388a.png)

3、MySQL选算了索引；

使用上面的说的“查询重写”的功能，给语句加上 force index。



总结：造成慢查询的原因中前面两种情况出现的次数最大，我们可以通过以下的过程预先发现问题：

1. 上线前，在测试环境，把慢查询日志slow log打开，并且把long_query_time设置成0，确保每个语句都被记录入慢查询日志；
2. 在测试表中插入模拟线上的数据，做一遍回归测试；
3. 观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。（我们在前面文章中已经多次用到过 Rows_examined 方法了，相信你已经动手尝试过了。如果还有不明白的，欢迎给我留言，我们一起讨论）。



###### QPS突增问题

解决方法：

1. 一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。
2. 如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。
3. 如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成"select 1"返回。

会存在两个副作用：

1. 如果别的功能里面也用到了这个SQL语句模板，会有误差。
2. 很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1 的结果返回的话，可能会导致后面的业务逻辑一起失败。

###### 自增id用完了怎么办？

- 表定义自增值 id

  表定义的自增值达到上限后的逻辑：再申请下一个id时，得到的值保持不变

  ```mysql
  
  create table t(id int unsigned auto_increment primary key) auto_increment=4294967295;
  insert into t values(null);
  //成功插入一行 4294967295
  show create table t;
  /* CREATE TABLE `t` (
    `id` int(10) unsigned NOT NULL AUTO_INCREMENT,
    PRIMARY KEY (`id`)
  ) ENGINE=InnoDB AUTO_INCREMENT=4294967295;
  */
  
  insert into t values(null);
  //Duplicate entry '4294967295' for key 'PRIMARY'
  ```

- InnoDB系统自增row_id

  InnoDB维护了一个全局的dict_sys.row_id，每插入一行数据，都将当前的dict_sys.row_id作为row_id，然后把dict_sys.row_id的值加上1；

  - row_id 写入表中的值范围，是从 0 到 2^48-1；

  - 当 dict_sys.row_id=2^48时，如果再有插入数据的行为要来申请 row_id，拿到以后再取最后 6 个字节的话就是
  - 也就是说，写入表的 row_id 是从 0 开始到 248-1。达到上限后，下一个值就是 0，然后继续循环。

- Xid

  MySQL 内部维护了一个全局变量 global_query_id，每次执行语句的时候将它赋值给 Query_id，然后给这个变量加 1。如果当前语句是这个事务执行的第一条语句，那么 MySQL 还会同时把 Query_id 赋值给这个事务的 Xid。

  而 global_query_id 是一个纯内存变量，重启之后就清零了。所以你就知道了，在同一个数据库实例中，不同事务的 Xid 也是有可能相同的。但是 MySQL 重启之后会重新生成新的 binlog 文件，这就保证了，同一个 binlog 文件里，Xid 一定是惟一的。

- Innodb trx_id

  Xid 是由 server 层维护的。InnoDB 内部使用 Xid，就是为了能够在 InnoDB 事务和 server 之间做关联。但是，InnoDB 自己的 trx_id，是另外维护的。

  InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。InnoDB 数据可见性的核心思想是：每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。

每种自增 id 有各自的应用场景，在达到上限后的表现也不同：

1. 表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。
2. row_id 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆盖之前的数据。
3. Xid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。
4. InnoDB 的 max_trx_id 递增值每次 MySQL 重启都会被保存起来，所以我们文章中提到的脏读的例子就是一个必现的 bug，好在留给我们的时间还很充裕。
5. thread_id 是我们使用中最常见的，而且也是处理得最好的一个自增 id 逻辑了。





MySQL实战45讲的PPT总结：https://github.com/zhangkekf/reading-notes/tree/master/MySQL%E6%95%B4%E7%90%86





